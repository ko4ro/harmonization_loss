{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLxMltZuhqoV"
      },
      "source": [
        "PyTorchでは、テンソルの勾配に対してさらに逆伝播を行うことが可能です。これは、勾配自体が別の計算グラフの一部として扱われ、その勾配を計算する際に役立ちます。このような操作を行うためには、torch.autograd.grad関数を使用し、create_graph=Trueを指定して計算グラフを構築する必要はある"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWGMxN2cwkW2",
        "outputId": "682bb20d-a49d-4713-b523-afc0f587bfda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: 2.0\n",
            "y: 4.0\n",
            "dy/dx: 4.0\n",
            "d^2y/dx^2: 2.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 入力テンソルの定義\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "# 順伝播の計算\n",
        "y = x ** 2  # y = x^2\n",
        "\n",
        "# yに対するxの勾配を計算\n",
        "grad_y = torch.autograd.grad(y, x, create_graph=True)[0]\n",
        "\n",
        "# grad_yに対するxの勾配を計算\n",
        "grad2_y = torch.autograd.grad(grad_y, x)[0]\n",
        "\n",
        "print(f\"x: {x.item()}\")\n",
        "print(f\"y: {y.item()}\")\n",
        "print(f\"dy/dx: {grad_y.item()}\")\n",
        "print(f\"d^2y/dx^2: {grad2_y.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANBJwCyXCsaL"
      },
      "source": [
        "# 2次元の簡易的に作成したテンソルで実験\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YH88xKTUKzm",
        "outputId": "72f4c2fb-3fd5-41ac-be4f-acd3f776bcc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 0.0666, w: [0.4382876  0.26491398]\n",
            "Epoch [20/100], Loss: 0.0269, w: [0.6151691 0.2922606]\n",
            "Epoch [30/100], Loss: 0.0165, w: [0.70722514 0.25977173]\n",
            "Epoch [40/100], Loss: 0.0108, w: [0.76744395 0.21765819]\n",
            "Epoch [50/100], Loss: 0.0072, w: [0.8123824  0.17890564]\n",
            "Epoch [60/100], Loss: 0.0048, w: [0.84785426 0.14606124]\n",
            "Epoch [70/100], Loss: 0.0032, w: [0.87643355 0.11893417]\n",
            "Epoch [80/100], Loss: 0.0021, w: [0.89961696 0.09673017]\n",
            "Epoch [90/100], Loss: 0.0014, w: [0.9184603  0.07861938]\n",
            "Epoch [100/100], Loss: 0.0009, w: [0.9337813  0.06387097]\n",
            "最終的な w: [0.9337813  0.06387097]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# TensorBoardの設定\n",
        "writer = SummaryWriter(log_dir=\"1tensor\")\n",
        "\n",
        "# データの生成\n",
        "torch.manual_seed(42)  # 再現性のためのシード値\n",
        "x1 = torch.linspace(0, 1, 100, dtype=torch.float32)  # x1: 線形\n",
        "x2 = torch.rand(100, dtype=torch.float32)  # x2: ランダム\n",
        "x = torch.stack([x1, x2], dim=1)  # 入力: [x1, x2]\n",
        "x.requires_grad_()  # 勾配計算を有効にする\n",
        "y = x1.clone()  # 出力は x1 のみ依存\n",
        "\n",
        "# モデルパラメータ [w1, w2]\n",
        "w = torch.nn.Parameter(torch.tensor([0.0, 0.0], requires_grad=True))\n",
        "\n",
        "# 損失関数とオプティマイザ\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD([w], lr=0.1)\n",
        "\n",
        "# 学習ループ\n",
        "for epoch in range(100):\n",
        "    # モデルの出力\n",
        "    y_pred = torch.matmul(x, w)  # y_pred = w1 * x1 + w2 * x2\n",
        "    # 損失計算\n",
        "    loss = criterion(y_pred, y)\n",
        "    dlossdx = torch.autograd.grad(loss, x, create_graph=True)[0]  # x に対する勾配を取得\n",
        "    # print(dlossdx.shape)\n",
        "    # loss2 = (dlossdx**2).sum()\n",
        "    loss2 = torch.max(dlossdx.abs())\n",
        "    # loss2 = torch.max(dlossdx.abs(), dim=1)[0].sum()\n",
        "    # loss = loss + loss2  # 損失に loss2 を加える\n",
        "\n",
        "    # 勾配計算と更新\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # TensorBoard に損失を記録\n",
        "    writer.add_scalar('Loss/Total Loss', loss.item(), epoch)\n",
        "    # writer.add_scalar('Loss/Loss1 (MSE)', criterion(y_pred, y).item(), epoch)\n",
        "    # writer.add_scalar('Loss/Loss2 (Grad Penalty)', loss2.item(), epoch)\n",
        "    # writer.add_scalar('Weights/w1', w[0].item(), epoch)\n",
        "    # writer.add_scalar('Weights/w2', w[1].item(), epoch)\n",
        "\n",
        "    # 進捗を出力\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}, w: {w.detach().numpy()}\")\n",
        "\n",
        "# TensorBoardを閉じる\n",
        "writer.close()\n",
        "\n",
        "# 学習結果\n",
        "print(f\"最終的な w: {w.detach().numpy()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21l30TRVvX12"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./1tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_0edlqTCm1s"
      },
      "source": [
        "# CIFAR10での実験"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_SB5pKVKZSL",
        "outputId": "75e83c52-bfa3-4a7f-fee7-ca636c60535f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-bbe6682b9470>:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(label)  # クラスラベル\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 2.0861, Learning Rate: 0.001000\n",
            "Epoch [2/10], Loss: 2.0627, Learning Rate: 0.001000\n",
            "Epoch [3/10], Loss: 2.0548, Learning Rate: 0.001000\n",
            "Epoch [4/10], Loss: 2.0488, Learning Rate: 0.001000\n",
            "Epoch [5/10], Loss: 2.0453, Learning Rate: 0.001000\n",
            "Epoch [6/10], Loss: 2.0417, Learning Rate: 0.001000\n",
            "Epoch [7/10], Loss: 2.0390, Learning Rate: 0.001000\n",
            "Epoch [8/10], Loss: 2.0357, Learning Rate: 0.001000\n",
            "Epoch [9/10], Loss: 2.0342, Learning Rate: 0.001000\n",
            "Epoch [10/10], Loss: 2.0322, Learning Rate: 0.001000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "num_epochs = 10  # 100エポックに設定\n",
        "use_loss2 = False  # dlossdxを使うかどうかを指定\n",
        "channel = 1 # coler\n",
        "batch_size = 1\n",
        "learning_rate = 0.001  # 初期学習率\n",
        "# TensorBoardの設定\n",
        "writer = SummaryWriter()\n",
        "\n",
        "# 画像の前処理\n",
        "if channel > 1:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((32, 32)),  # 画像サイズの統一\n",
        "      transforms.ToTensor(),  # テンソルに変換\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # RGBの各チャンネルを正規化\n",
        "  ])\n",
        "else:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Grayscale(num_output_channels=1),  # 白黒画像に変換（チャンネル数を1に）\n",
        "      transforms.Resize((32, 32)),  # 画像サイズの統一\n",
        "      transforms.ToTensor(),  # テンソルに変換\n",
        "      transforms.Normalize((0.5,), (0.5,))  # 正規化\n",
        "  ])\n",
        "# CIFAR-10 データセットのダウンロードとデータローダーの作成\n",
        "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 画像分類モデルの定義\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(ImageClassifier, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, num_classes, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# モデルのインスタンス化\n",
        "input_size = 32 * 32 * channel  # RGB画像を1Dにフラット化\n",
        "num_classes = 10  # CIFAR-10は10クラス分類\n",
        "model = ImageClassifier(input_size, num_classes)\n",
        "\n",
        "# オプティマイザとスケジューラの定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 10エポックごとに学習率を0.1倍に減衰\n",
        "\n",
        "# 中心16×16のマスクを作成\n",
        "mask = torch.zeros((batch_size, channel, 32, 32))\n",
        "mask[:, :, 8:24, 8:24] = 1  # 中心領域を1に設定\n",
        "mask = mask.view(-1, input_size)  # (1, 3072) 形式に変換\n",
        "\n",
        "# トレーニングループの開始\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    for image, label in dataloader:\n",
        "        image.requires_grad_()\n",
        "        x = image.view(-1, input_size)  # 画像を1Dに変換\n",
        "        target = torch.tensor(label)  # クラスラベル\n",
        "\n",
        "        # 順伝播\n",
        "        output = model(x)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        if use_loss2:\n",
        "            # dloss/dxの計算\n",
        "            dlossdx = torch.autograd.grad(loss, x, create_graph=True)[0]\n",
        "\n",
        "            # 中心領域の勾配に注目した二次損失の計算\n",
        "            focused_dlossdx = dlossdx * mask\n",
        "            loss2 = (focused_dlossdx**2).sum()\n",
        "\n",
        "            # 総合的な損失の計算\n",
        "            alpha = 1.0  # 重み付け係数\n",
        "            total_loss = loss  + alpha * loss2\n",
        "        else:\n",
        "            total_loss = loss\n",
        "\n",
        "        # 勾配の初期化、バックプロパゲーション、パラメータの更新\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 損失の蓄積\n",
        "        epoch_loss += total_loss.item()\n",
        "    # 学習率スケジューラを更新\n",
        "    # lr_scheduler.step()\n",
        "    # TensorBoardに記録\n",
        "    average_loss = epoch_loss / len(dataloader)\n",
        "    writer.add_scalar('Loss/With Loss2' if use_loss2 else 'Loss/Without Loss2', average_loss, epoch)\n",
        "\n",
        "    writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "# TensorBoardを閉じる\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "z9lDWt6rjYaV",
        "outputId": "1cfd1d4e-c9b5-471f-b22c-5c08560b6668"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-8df905ca168f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compile_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_dead_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_pointless_jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP_SUPPORTED_MODULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrap_if_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from .variables import (\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/variables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariableTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuiltin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnumVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/variables/builtin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mctx_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStreamVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m from .dicts import (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3572\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3574\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_epochs = 20\n",
        "use_loss2 = True\n",
        "channel = 1\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "alpha = 0.5\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1_input_size = 64 * 16 * 16\n",
        "        self.fc1 = nn.Linear(self.fc1_input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNNClassifier(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "def create_mask(batch_size, channel, height, width, mask_size=16):\n",
        "    mask = torch.zeros((batch_size, channel, height, width)).to(device)\n",
        "    start = (height - mask_size) // 2\n",
        "    end = start + mask_size\n",
        "    mask[:, :, start:end, start:end] = 1\n",
        "    return mask\n",
        "\n",
        "val_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def visualize_weights(model, writer, epoch):\n",
        "    with torch.no_grad():\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name and param.dim() == 4:\n",
        "                weight_np = param.cpu().numpy()\n",
        "                fig, ax = plt.subplots()\n",
        "                heatmap = np.mean(weight_np, axis=(0, 1))\n",
        "                img = ax.imshow(heatmap, cmap='jet', alpha=0.5)\n",
        "                plt.colorbar(img)\n",
        "                plt.title(f\"{name} Weights Heatmap\")\n",
        "                writer.add_figure(f\"Weights/{name}\", fig, global_step=epoch)\n",
        "                plt.close(fig)\n",
        "\n",
        "def evaluate_model(model, dataloader, writer, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    val_loss /= len(dataloader)\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/Validation', accuracy, epoch)\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    model.train()\n",
        "    for image, label in dataloader:\n",
        "        batch_size = image.size(0)\n",
        "        mask = create_mask(batch_size, channel, 32, 32)\n",
        "        image, label = image.to(device), label.to(device)\n",
        "        image.requires_grad_()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        if use_loss2:\n",
        "            dlossdx = torch.autograd.grad(outputs=output.mean(), inputs=image, create_graph=True)[0]\n",
        "            focused_dlossdx = dlossdx * mask\n",
        "            loss2 = (focused_dlossdx**2).sum() / (mask.sum() + 1e-8)\n",
        "            total_loss = loss + alpha * loss2\n",
        "        else:\n",
        "            total_loss = loss\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += total_loss.item()\n",
        "    average_loss = epoch_loss / len(dataloader)\n",
        "    scheduler.step(average_loss)\n",
        "    writer.add_scalar('Loss/With Loss2' if use_loss2 else 'Loss/Without Loss2', average_loss, epoch)\n",
        "    writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        evaluate_model(model, val_dataloader, writer, epoch)\n",
        "        visualize_weights(model, writer, epoch)\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "lH4KDfhEwrgH",
        "outputId": "29af4c16-5388-4bd3-85c0-baf9f77b7dc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mko4ro\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:\n",
            "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:\n",
            "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/wandb/run-20250220_063057-msv0fx1i</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ko4ro/cnn-cifar10/runs/msv0fx1i' target=\"_blank\">feasible-vortex-6</a></strong> to <a href='https://wandb.ai/ko4ro/cnn-cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ko4ro/cnn-cifar10' target=\"_blank\">https://wandb.ai/ko4ro/cnn-cifar10</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ko4ro/cnn-cifar10/runs/msv0fx1i' target=\"_blank\">https://wandb.ai/ko4ro/cnn-cifar10/runs/msv0fx1i</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:11<00:00, 14761002.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import wandb\n",
        "\n",
        "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g5tDGOygUStu"
      },
      "outputs": [],
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1_input_size = 64 * 16 * 16\n",
        "        self.fc1 = nn.Linear(self.fc1_input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNNClassifier(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_center_mask(batch_size, channel, height, width):\n",
        "    mask = torch.zeros((batch_size, channel, height, width)).to(device)\n",
        "    grid_size = int(batch_size ** 0.5)  # 3x3 grid for batch size 9\n",
        "    center_index = batch_size // 2  # Index of the center image in 3x3 grid\n",
        "    mask[center_index, :, :, :] = 1  # Only the center image gets a mask\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 検証データの評価（Val Loss と Accuracy の記録を追加）\n",
        "def evaluate_model(model, dataloader, criterion, writer, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    val_loss /= len(dataloader)\n",
        "    wandb.log({\"val_loss\": val_loss,  \"epoch\": epoch})\n",
        "    wandb.log({\"val_acc\": accuracy,  \"epoch\": epoch})\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/Validation', accuracy, epoch)\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.init(project=\"cnn-cifar10\", config={\n",
        "    \"epochs\": 20,\n",
        "    \"batch_size\": 9,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"alpha\": 0.01,\n",
        "})\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = wandb.config[\"epochs\"]\n",
        "use_loss2 = True\n",
        "channel = 1\n",
        "batch_size = wandb.config[\"batch_size\"]\n",
        "learning_rate = wandb.config[\"learning_rate\"]\n",
        "alpha = wandb.config[\"alpha\"]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 1.1759, Learning Rate: 0.001000\n",
            "Epoch [2/20], Loss: 1.1544, Learning Rate: 0.001000\n",
            "Epoch [3/20], Loss: 1.1361, Learning Rate: 0.001000\n",
            "Epoch [4/20], Loss: 1.1211, Learning Rate: 0.001000\n",
            "Epoch [5/20], Loss: 1.1117, Learning Rate: 0.001000\n",
            "Validation Loss: 1.0464, Validation Accuracy: 63.27%\n",
            "Epoch [6/20], Loss: 1.1009, Learning Rate: 0.001000\n",
            "Epoch [7/20], Loss: 1.0822, Learning Rate: 0.001000\n",
            "Epoch [8/20], Loss: 1.0789, Learning Rate: 0.001000\n",
            "Epoch [9/20], Loss: 1.0681, Learning Rate: 0.001000\n",
            "Epoch [10/20], Loss: 1.0625, Learning Rate: 0.001000\n",
            "Validation Loss: 1.0538, Validation Accuracy: 63.21%\n",
            "Epoch [11/20], Loss: 1.0595, Learning Rate: 0.001000\n",
            "Epoch [12/20], Loss: 1.0588, Learning Rate: 0.001000\n",
            "Epoch [13/20], Loss: 1.0506, Learning Rate: 0.001000\n",
            "Epoch [14/20], Loss: 1.0430, Learning Rate: 0.001000\n",
            "Epoch [15/20], Loss: 1.0339, Learning Rate: 0.001000\n",
            "Validation Loss: 0.9924, Validation Accuracy: 65.56%\n",
            "Epoch [16/20], Loss: 1.0350, Learning Rate: 0.001000\n",
            "Epoch [17/20], Loss: 1.0342, Learning Rate: 0.001000\n",
            "Epoch [18/20], Loss: 1.0257, Learning Rate: 0.001000\n",
            "Epoch [19/20], Loss: 1.0217, Learning Rate: 0.001000\n",
            "Epoch [20/20], Loss: 1.0221, Learning Rate: 0.001000\n",
            "Validation Loss: 1.0027, Validation Accuracy: 64.98%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇████</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁█▆</td></tr><tr><td>val_loss</td><td>▇█▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_loss</td><td>1.02206</td></tr><tr><td>val_acc</td><td>64.98</td></tr><tr><td>val_loss</td><td>1.00275</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">feasible-vortex-6</strong> at: <a href='https://wandb.ai/ko4ro/cnn-cifar10/runs/msv0fx1i' target=\"_blank\">https://wandb.ai/ko4ro/cnn-cifar10/runs/msv0fx1i</a><br> View project at: <a href='https://wandb.ai/ko4ro/cnn-cifar10' target=\"_blank\">https://wandb.ai/ko4ro/cnn-cifar10</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code></code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    model.train()\n",
        "    for image, label in dataloader:\n",
        "        batch_size = image.size(0)\n",
        "        mask = create_center_mask(batch_size, channel, 32, 32)\n",
        "        image, label = image.to(device), label.to(device)\n",
        "        image.requires_grad_()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        if use_loss2:\n",
        "            dlossdx = torch.autograd.grad(outputs=output.mean(), inputs=image, create_graph=True)[0]\n",
        "            focused_dlossdx = dlossdx * mask\n",
        "            loss2 = (focused_dlossdx**2).sum() / (mask.sum() + 1e-8)\n",
        "            total_loss = loss + alpha * loss2\n",
        "            # loss2 = loss2 / loss2.detach()  # 正規化してエネルギーを1に\n",
        "            # lambda_energy = 0.1  # 制約の強さ\n",
        "            # constraint_loss = lambda_energy * (loss2 - 1) ** 2\n",
        "            # total_loss = loss + alpha * loss2 + constraint_loss\n",
        "        else:\n",
        "            total_loss = loss\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += total_loss.item()\n",
        "    average_loss = epoch_loss / len(dataloader)\n",
        "    scheduler.step(average_loss)\n",
        "    wandb.log({\"train_loss\": average_loss, \"lr\": optimizer.param_groups[0]['lr'], \"epoch\": epoch})\n",
        "    writer.add_scalar(\"Loss/train\", average_loss, epoch)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        evaluate_model(model, val_dataloader, criterion, writer, epoch)\n",
        "writer.close()\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
